import os
import sys
import unittest
import uuid
from datetime import datetime

import numpy as np
import pandas as pd

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from trading.agents.model_builder_agent import ModelBuilderAgent as ModelBuilder
from trading.agents.prompt_router_agent import PromptRouterAgent as AgentRouter
from trading.agents.self_improving_agent import SelfImprovingAgent
from trading.agents.task_dashboard import TaskDashboard
from trading.agents.task_memory import Task, TaskMemory, TaskStatus


class TestRealWorldScenario(unittest.TestCase):
    def setUp(self):
        """Set up test environment before each test."""
        self.task_memory = TaskMemory()
        self.dashboard = TaskDashboard(self.task_memory)
        self.model_builder = ModelBuilder()
        self.agent_router = AgentRouter()
        self.self_improving_agent = SelfImprovingAgent()

        # Create sample market data
        self.market_data = self._generate_sample_market_data()

    def _generate_sample_market_data(self):
        """Generate realistic sample market data."""
        dates = pd.date_range(start="2024-01-01", periods=100, freq="D")
        base_price = 100
        volatility = 0.02

        # Generate price series with trend and seasonality
        trend = np.linspace(0, 20, len(dates))
        seasonality = 5 * np.sin(np.linspace(0, 4 * np.pi, len(dates)))
        noise = np.random.normal(0, volatility, len(dates))

        prices = base_price + trend + seasonality + noise
        volumes = np.random.normal(1000, 100, len(dates))

        return pd.DataFrame({"timestamp": dates, "price": prices, "volume": volumes})

    def test_complete_trading_workflow(self):
        """Test a complete trading system workflow with task tracking."""
        # 1. Model Training Phase
        training_tasks = self._run_model_training_phase()
        self._verify_training_tasks(training_tasks)

        # 2. Forecasting Phase
        forecast_tasks = self._run_forecasting_phase()
        self._verify_forecast_tasks(forecast_tasks)

        # 3. Strategy Development Phase
        strategy_tasks = self._run_strategy_development_phase()
        self._verify_strategy_tasks(strategy_tasks)

        # 4. Performance Analysis Phase
        analysis_tasks = self._run_performance_analysis_phase()
        self._verify_analysis_tasks(analysis_tasks)

        # 5. Self-Improvement Phase
        improvement_tasks = self._run_self_improvement_phase()
        self._verify_improvement_tasks(improvement_tasks)

    def _run_model_training_phase(self):
        """Run the model training phase and return created tasks."""
        training_tasks = []

        # Train different model types
        model_types = ["lstm", "xgboost", "prophet", "garch", "ridge", "hybrid"]
        for model_type in model_types:
            task_id = str(uuid.uuid4())
            task = Task(
                task_id=task_id,
                type="model_training",
                status=TaskStatus.PENDING,
                metadata={
                    "agent": "model_builder",
                    "creation_time": datetime.now().isoformat(),
                    "model_type": model_type,
                },
                notes=f"Training {model_type} model",
            )
            self.task_memory.add_task(task)
            training_tasks.append(task)

            try:
                # Run appropriate model
                if model_type == "lstm":
                    result = self.model_builder.run_lstm(self.market_data)
                elif model_type == "xgboost":
                    result = self.model_builder.run_xgboost(self.market_data)
                elif model_type == "prophet":
                    result = self.model_builder.run_prophet(self.market_data)
                elif model_type == "garch":
                    result = self.model_builder.run_garch(self.market_data)
                elif model_type == "ridge":
                    result = self.model_builder.run_ridge(self.market_data)
                else:  # hybrid
                    result = self.model_builder.run_hybrid(self.market_data)

                # Update task status
                task.status = TaskStatus.COMPLETED
                task.metadata.update(
                    {
                        "completion_time": datetime.now().isoformat(),
                        "duration": "5 minutes",
                        "metrics": {
                            "mse": result.metrics.mse,
                            "sharpe_ratio": result.metrics.sharpe_ratio,
                            "max_drawdown": result.metrics.max_drawdown,
                        },
                    }
                )

            except Exception as e:
                task.status = TaskStatus.FAILED
                task.metadata.update({"error": str(e), "completion_time": datetime.now().isoformat()})

            self.task_memory.update_task(task)

        return training_tasks

    def _run_forecasting_phase(self):
        """Run the forecasting phase and return created tasks."""
        forecast_tasks = []

        # Generate forecasts using different models
        for i in range(3):  # Generate 3 forecasts
            task_id = str(uuid.uuid4())
            task = Task(
                task_id=task_id,
                type="forecast",
                status=TaskStatus.PENDING,
                metadata={"agent": "forecast_agent", "creation_time": datetime.now().isoformat(), "forecast_id": i},
                notes=f"Generating forecast {i}",
            )
            self.task_memory.add_task(task)
            forecast_tasks.append(task)

            try:
                # Simulate forecast generation
                forecast_result = self.agent_router._handle_forecast(
                    self.market_data, "Generate price forecast for next 7 days"
                )

                task.status = TaskStatus.COMPLETED
                task.metadata.update(
                    {
                        "completion_time": datetime.now().isoformat(),
                        "duration": "2 minutes",
                        "forecast_data": forecast_result.data,
                    }
                )

            except Exception as e:
                task.status = TaskStatus.FAILED
                task.metadata.update({"error": str(e), "completion_time": datetime.now().isoformat()})

            self.task_memory.update_task(task)

        return forecast_tasks

    def _run_strategy_development_phase(self):
        """Run the strategy development phase and return created tasks."""
        strategy_tasks = []

        # Develop different trading strategies
        strategy_types = ["trend_following", "mean_reversion", "breakout"]
        for strategy_type in strategy_types:
            task_id = str(uuid.uuid4())
            task = Task(
                task_id=task_id,
                type="strategy_development",
                status=TaskStatus.PENDING,
                metadata={
                    "agent": "strategy_agent",
                    "creation_time": datetime.now().isoformat(),
                    "strategy_type": strategy_type,
                },
                notes=f"Developing {strategy_type} strategy",
            )
            self.task_memory.add_task(task)
            strategy_tasks.append(task)

            try:
                # Simulate strategy development
                strategy_result = self.agent_router._handle_strategy(
                    self.market_data, f"Develop {strategy_type} trading strategy"
                )

                task.status = TaskStatus.COMPLETED
                task.metadata.update(
                    {
                        "completion_time": datetime.now().isoformat(),
                        "duration": "3 minutes",
                        "strategy_data": strategy_result.data,
                    }
                )

            except Exception as e:
                task.status = TaskStatus.FAILED
                task.metadata.update({"error": str(e), "completion_time": datetime.now().isoformat()})

            self.task_memory.update_task(task)

        return strategy_tasks

    def _run_performance_analysis_phase(self):
        """Run the performance analysis phase and return created tasks."""
        task_id = str(uuid.uuid4())
        task = Task(
            task_id=task_id,
            type="performance_analysis",
            status=TaskStatus.PENDING,
            metadata={"agent": "analysis_agent", "creation_time": datetime.now().isoformat()},
            notes="Analyzing system performance",
        )
        self.task_memory.add_task(task)

        try:
            # Simulate performance analysis
            analysis_result = self.self_improving_agent.analyze_performance()

            task.status = TaskStatus.COMPLETED
            task.metadata.update(
                {
                    "completion_time": datetime.now().isoformat(),
                    "duration": "4 minutes",
                    "analysis_data": analysis_result,
                }
            )

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.metadata.update({"error": str(e), "completion_time": datetime.now().isoformat()})

        self.task_memory.update_task(task)
        return [task]

    def _run_self_improvement_phase(self):
        """Run the self-improvement phase and return created tasks."""
        task_id = str(uuid.uuid4())
        task = Task(
            task_id=task_id,
            type="self_improvement",
            status=TaskStatus.PENDING,
            metadata={"agent": "self_improving_agent", "creation_time": datetime.now().isoformat()},
            notes="Running self-improvement cycle",
        )
        self.task_memory.add_task(task)

        try:
            # Simulate self-improvement cycle
            improvement_result = self.self_improving_agent.run_self_improvement()

            task.status = TaskStatus.COMPLETED
            task.metadata.update(
                {
                    "completion_time": datetime.now().isoformat(),
                    "duration": "5 minutes",
                    "improvement_data": improvement_result,
                }
            )

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.metadata.update({"error": str(e), "completion_time": datetime.now().isoformat()})

        self.task_memory.update_task(task)
        return [task]

    def _verify_training_tasks(self, tasks):
        """Verify model training tasks."""
        completed_tasks = [t for t in tasks if t.status == TaskStatus.COMPLETED]
        self.assertGreater(len(completed_tasks), 0, "No completed training tasks")

        for task in completed_tasks:
            self.assertIn("metrics", task.metadata)
            self.assertIn("mse", task.metadata["metrics"])
            self.assertIn("sharpe_ratio", task.metadata["metrics"])

    def _verify_forecast_tasks(self, tasks):
        """Verify forecasting tasks."""
        completed_tasks = [t for t in tasks if t.status == TaskStatus.COMPLETED]
        self.assertGreater(len(completed_tasks), 0, "No completed forecast tasks")

        for task in completed_tasks:
            self.assertIn("forecast_data", task.metadata)

    def _verify_strategy_tasks(self, tasks):
        """Verify strategy development tasks."""
        completed_tasks = [t for t in tasks if t.status == TaskStatus.COMPLETED]
        self.assertGreater(len(completed_tasks), 0, "No completed strategy tasks")

        for task in completed_tasks:
            self.assertIn("strategy_data", task.metadata)

    def _verify_analysis_tasks(self, tasks):
        """Verify performance analysis tasks."""
        completed_tasks = [t for t in tasks if t.status == TaskStatus.COMPLETED]
        self.assertGreater(len(completed_tasks), 0, "No completed analysis tasks")

        for task in completed_tasks:
            self.assertIn("analysis_data", task.metadata)

    def _verify_improvement_tasks(self, tasks):
        """Verify self-improvement tasks."""
        completed_tasks = [t for t in tasks if t.status == TaskStatus.COMPLETED]
        self.assertGreater(len(completed_tasks), 0, "No completed improvement tasks")

        for task in completed_tasks:
            self.assertIn("improvement_data", task.metadata)


if __name__ == "__main__":
    unittest.main()
